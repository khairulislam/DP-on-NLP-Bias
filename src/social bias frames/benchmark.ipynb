{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'social bias frames'\n",
    "model_name = 'bert'\n",
    "result_folder = f'../../results/{dataset_name}'\n",
    "test_csv_filepath = os.path.join(result_folder, 'test.csv')\n",
    "\n",
    "model_folder = f'{result_folder}/{model_name}' # for this particular model\n",
    "result_filepath = os.path.join(model_folder, 'results.csv')\n",
    "dp_result_filepath = os.path.join(model_folder, 'results_dp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "The dataset can be preprocessed from the original dataset to be used here. To simplify things, I saved the preprocessed datasets during the tokenizing process as csv files and then downloaded them in the corresponding dataset folder of [`result`](../results/) directory.\n",
    "\n",
    "You can recreate the processed datasets using the tokenize notebooks for that particular dataset. That would give you train, test and validation csv files as well as the tokenized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv(result_filepath)\n",
    "dp_result = pd.read_csv(dp_result_filepath)\n",
    "df = pd.read_csv(test_csv_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>HITId</th>\n",
       "      <th>post</th>\n",
       "      <th>labels</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3DA79LNS59PNAW62RLUHAOPS7E2T38</td>\n",
       "      <td>Fuc u say ? &amp;#8220;@AyyyeThatsChubb: All these hoes look good on IG&amp;#8221; http://t.co/PlsFL84cDp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3OQQD2WO8I0X1IQRX9VDWHNJWXN3I2</td>\n",
       "      <td>Yo hoe is like a tick so she hunting for a blood</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                           HITId  \\\n",
       "0      0  3DA79LNS59PNAW62RLUHAOPS7E2T38   \n",
       "1      1  3OQQD2WO8I0X1IQRX9VDWHNJWXN3I2   \n",
       "\n",
       "                                                                                                post  \\\n",
       "0  Fuc u say ? &#8220;@AyyyeThatsChubb: All these hoes look good on IG&#8221; http://t.co/PlsFL84cDp   \n",
       "1                                                   Yo hoe is like a tick so she hunting for a blood   \n",
       "\n",
       "   labels  male  female  white  black  \n",
       "0     1.0   0.0     0.0    0.0    0.0  \n",
       "1     1.0   0.0     0.0    0.0    0.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only calculate test result\n",
    "result = result[result['split']=='test']\n",
    "dp_result = dp_result[dp_result['split']=='test']\n",
    "\n",
    "# drop split column\n",
    "result.drop(columns=['split'], inplace=True)\n",
    "dp_result.drop(columns=['split'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result has id column which is the same as the text ids from raw dataset\n",
    "df.rename({'index': id_column}, axis=1, inplace=True)\n",
    "df.drop(columns=['labels'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.merge(df, on=id_column, how='inner').reset_index(drop=True)\n",
    "dp_result = dp_result.merge(df, on=id_column, how='inner').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "      <th>probs</th>\n",
       "      <th>HITId</th>\n",
       "      <th>post</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.617603</td>\n",
       "      <td>3DA79LNS59PNAW62RLUHAOPS7E2T38</td>\n",
       "      <td>Fuc u say ? &amp;#8220;@AyyyeThatsChubb: All these hoes look good on IG&amp;#8221; http://t.co/PlsFL84cDp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.810559</td>\n",
       "      <td>3OQQD2WO8I0X1IQRX9VDWHNJWXN3I2</td>\n",
       "      <td>Yo hoe is like a tick so she hunting for a blood</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.677522</td>\n",
       "      <td>32PT7WK7DM9GT7A55VU25K764SF3D0</td>\n",
       "      <td>When u hitting it from the back u gotta call her \"bitch\" they love that but don't u dare call em \"slut\"</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.374349</td>\n",
       "      <td>3ZFRE2BDQ98VC6MFH2QN3SFDZ5PXZS</td>\n",
       "      <td>Studying for this bio test like a hoe &amp;#128554;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.789070</td>\n",
       "      <td>38F60IALAGBRT4758YCY8QRL42IT0D</td>\n",
       "      <td>You niggas talking to these females trying to get some pussy but dont realize you're only boosting their ego and getting curved.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  labels     probs                           HITId  \\\n",
       "0   0       1  0.617603  3DA79LNS59PNAW62RLUHAOPS7E2T38   \n",
       "1   1       1  0.810559  3OQQD2WO8I0X1IQRX9VDWHNJWXN3I2   \n",
       "2   2       1  0.677522  32PT7WK7DM9GT7A55VU25K764SF3D0   \n",
       "3   3       1  0.374349  3ZFRE2BDQ98VC6MFH2QN3SFDZ5PXZS   \n",
       "4   4       1  0.789070  38F60IALAGBRT4758YCY8QRL42IT0D   \n",
       "\n",
       "                                                                                                                               post  \\\n",
       "0                                 Fuc u say ? &#8220;@AyyyeThatsChubb: All these hoes look good on IG&#8221; http://t.co/PlsFL84cDp   \n",
       "1                                                                                  Yo hoe is like a tick so she hunting for a blood   \n",
       "2                           When u hitting it from the back u gotta call her \"bitch\" they love that but don't u dare call em \"slut\"   \n",
       "3                                                                                   Studying for this bio test like a hoe &#128554;   \n",
       "4  You niggas talking to these females trying to get some pussy but dont realize you're only boosting their ego and getting curved.   \n",
       "\n",
       "   male  female  white  black  \n",
       "0   0.0     0.0    0.0    0.0  \n",
       "1   0.0     0.0    0.0    0.0  \n",
       "2   0.0     1.0    0.0    0.0  \n",
       "3   0.0     0.0    0.0    0.0  \n",
       "4   0.0     1.0    0.0    0.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# this adds the src folder in the sys path, where the metric_utils.py file is\n",
    "# not needed if this notebook is in the same folder\n",
    "sys.path.append( '..' )\n",
    "from metric_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert probability to prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[prediction_column] = result[probability_column] >=0.5\n",
    "dp_result[prediction_column] = dp_result[probability_column] >=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['female', 'male', 'black', 'white']\n"
     ]
    }
   ],
   "source": [
    "group_map = {\n",
    "    'gender': {\n",
    "        'unprivileged':['female'],\n",
    "        'privileged':['male']\n",
    "    },\n",
    "    'race': {\n",
    "        'unprivileged':['black'],\n",
    "        'privileged': ['white']\n",
    "    }\n",
    "}\n",
    "\n",
    "identities = []\n",
    "for group_key in group_map.keys():\n",
    "    subgroup_map = group_map[group_key]\n",
    "    for subgroup_key in subgroup_map.keys():\n",
    "        identities.extend(subgroup_map[subgroup_key])\n",
    "\n",
    "print(identities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarize identity and target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = binarize(result, [target_column] + identities)\n",
    "dp_result = binarize(dp_result, [target_column] + identities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female\n",
      "True    355\n",
      "Name: labels, dtype: int64\n",
      "male\n",
      "True    46\n",
      "Name: labels, dtype: int64\n",
      "black\n",
      "True     602\n",
      "False      1\n",
      "Name: labels, dtype: int64\n",
      "white\n",
      "True    7\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for indentity in identities:\n",
    "    print(indentity)\n",
    "    print(result[result[indentity]][target_column].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning ! No negative examples found\n",
      "Warning ! No negative examples found\n",
      "Warning ! No negative examples found\n",
      "Warning ! No negative examples found\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Data-Privacy-Project\\src\\social bias frames\\benchmark.ipynb Cell 24'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Data-Privacy-Project/src/social%20bias%20frames/benchmark.ipynb#ch0000024?line=9'>10</a>\u001b[0m    privileged_group \u001b[39m=\u001b[39m subgroup_map[\u001b[39m'\u001b[39m\u001b[39mprivileged\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Data-Privacy-Project/src/social%20bias%20frames/benchmark.ipynb#ch0000024?line=10'>11</a>\u001b[0m    unprivileged_group \u001b[39m=\u001b[39m subgroup_map[\u001b[39m'\u001b[39m\u001b[39munprivileged\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Data-Privacy-Project/src/social%20bias%20frames/benchmark.ipynb#ch0000024?line=12'>13</a>\u001b[0m    bias_results[group_key] \u001b[39m=\u001b[39m calculate_bias(result, privileged_group, unprivileged_group)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Data-Privacy-Project/src/social%20bias%20frames/benchmark.ipynb#ch0000024?line=13'>14</a>\u001b[0m    bias_results[group_key\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_DP\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m calculate_bias(dp_result, privileged_group, unprivileged_group)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Data-Privacy-Project/src/social%20bias%20frames/benchmark.ipynb#ch0000024?line=15'>16</a>\u001b[0m bias_results \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(bias_results) \n",
      "File \u001b[1;32md:\\Data-Privacy-Project\\src\\social bias frames\\..\\metric_utils.py:79\u001b[0m, in \u001b[0;36mcalculate_bias\u001b[1;34m(df, privileged_group, unprivileged_group)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Data-Privacy-Project/src/social%20bias%20frames/../metric_utils.py?line=75'>76</a>\u001b[0m df_unprivileged \u001b[39m=\u001b[39m df[(df[unprivileged_group])\u001b[39m.\u001b[39many(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)]\n\u001b[0;32m     <a href='file:///d%3A/Data-Privacy-Project/src/social%20bias%20frames/../metric_utils.py?line=77'>78</a>\u001b[0m demographic_parity \u001b[39m=\u001b[39m calculate_demographic_parity(df_privileged, df_unprivileged)\n\u001b[1;32m---> <a href='file:///d%3A/Data-Privacy-Project/src/social%20bias%20frames/../metric_utils.py?line=78'>79</a>\u001b[0m EqOpp1, EqOpp0, EqOdd \u001b[39m=\u001b[39m calculate_equality(df_privileged, df_unprivileged)\n\u001b[0;32m     <a href='file:///d%3A/Data-Privacy-Project/src/social%20bias%20frames/../metric_utils.py?line=79'>80</a>\u001b[0m accuracy_unprivileged, accuracy_privileged, accuracy \u001b[39m=\u001b[39m calculate_sensitive_accuracy(df_privileged, df_unprivileged)\n\u001b[0;32m     <a href='file:///d%3A/Data-Privacy-Project/src/social%20bias%20frames/../metric_utils.py?line=81'>82</a>\u001b[0m biases \u001b[39m=\u001b[39m [demographic_parity, EqOpp1, EqOpp0, EqOdd, accuracy_unprivileged, accuracy_privileged, accuracy]\n",
      "File \u001b[1;32md:\\Data-Privacy-Project\\src\\social bias frames\\..\\metric_utils.py:55\u001b[0m, in \u001b[0;36mcalculate_equality\u001b[1;34m(df_privileged, df_unprivileged)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Data-Privacy-Project/src/social%20bias%20frames/../metric_utils.py?line=53'>54</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalculate_equality\u001b[39m(df_privileged, df_unprivileged):\n\u001b[1;32m---> <a href='file:///d%3A/Data-Privacy-Project/src/social%20bias%20frames/../metric_utils.py?line=54'>55</a>\u001b[0m     fpr_privileged \u001b[39m=\u001b[39m false_positive_rate(df_privileged[target_column], df_privileged[prediction_column])\n\u001b[0;32m     <a href='file:///d%3A/Data-Privacy-Project/src/social%20bias%20frames/../metric_utils.py?line=55'>56</a>\u001b[0m     tpr_privileged \u001b[39m=\u001b[39m true_positive_rate(df_privileged[target_column], df_privileged[prediction_column])\n\u001b[0;32m     <a href='file:///d%3A/Data-Privacy-Project/src/social%20bias%20frames/../metric_utils.py?line=57'>58</a>\u001b[0m     fpr_unprivileged \u001b[39m=\u001b[39m false_positive_rate(df_unprivileged[target_column], df_unprivileged[prediction_column])\n",
      "File \u001b[1;32md:\\Data-Privacy-Project\\src\\social bias frames\\..\\metric_utils.py:17\u001b[0m, in \u001b[0;36mfalse_positive_rate\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Data-Privacy-Project/src/social%20bias%20frames/../metric_utils.py?line=15'>16</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfalse_positive_rate\u001b[39m(y_true, y_pred):\n\u001b[1;32m---> <a href='file:///d%3A/Data-Privacy-Project/src/social%20bias%20frames/../metric_utils.py?line=16'>17</a>\u001b[0m     tn, fp, fn, tp \u001b[39m=\u001b[39m confusion_matrix(y_true, y_pred)\u001b[39m.\u001b[39mravel()\n\u001b[0;32m     <a href='file:///d%3A/Data-Privacy-Project/src/social%20bias%20frames/../metric_utils.py?line=17'>18</a>\u001b[0m     negatives \u001b[39m=\u001b[39m fp\u001b[39m+\u001b[39mtn\n\u001b[0;32m     <a href='file:///d%3A/Data-Privacy-Project/src/social%20bias%20frames/../metric_utils.py?line=18'>19</a>\u001b[0m     \u001b[39mif\u001b[39;00m negatives \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 1)"
     ]
    }
   ],
   "source": [
    "bias_results = {\n",
    "   # make sure your calculate bias method returns bias metrics in the same order\n",
    "   'fairness_metrics': ['demographic parity', 'Equality of Opportunity (w.r.t y = 1)',\n",
    "'Equality of Opportunity (w.r.t y = 0)', 'Equality of Odds', 'unprotected-accuracy',\n",
    "'protected-accuracy', 'accuracy']\n",
    "}\n",
    "\n",
    "for group_key in group_map.keys():\n",
    "   subgroup_map = group_map[group_key]\n",
    "   privileged_group = subgroup_map['privileged']\n",
    "   unprivileged_group = subgroup_map['unprivileged']\n",
    "\n",
    "   bias_results[group_key] = calculate_bias(result, privileged_group, unprivileged_group)\n",
    "   bias_results[group_key+'_DP'] = calculate_bias(dp_result, privileged_group, unprivileged_group)\n",
    "\n",
    "bias_results = pd.DataFrame(bias_results) \n",
    "bias_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_results.to_csv(os.path.join(model_folder, 'bias.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Data-Privacy-Project\\src\\social bias frames\\benchmark.ipynb Cell 27'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Data-Privacy-Project/src/social%20bias%20frames/benchmark.ipynb#ch0000027?line=9'>10</a>\u001b[0m privileged_group_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(privileged_group)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Data-Privacy-Project/src/social%20bias%20frames/benchmark.ipynb#ch0000027?line=10'>11</a>\u001b[0m unprivileged_group_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(unprivileged_group)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Data-Privacy-Project/src/social%20bias%20frames/benchmark.ipynb#ch0000027?line=12'>13</a>\u001b[0m overall_results[privileged_group_name] \u001b[39m=\u001b[39m calculate_metrics(result, privileged_group)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Data-Privacy-Project/src/social%20bias%20frames/benchmark.ipynb#ch0000027?line=13'>14</a>\u001b[0m overall_results[privileged_group_name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_DP\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m calculate_metrics(dp_result, privileged_group)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Data-Privacy-Project/src/social%20bias%20frames/benchmark.ipynb#ch0000027?line=15'>16</a>\u001b[0m overall_results[unprivileged_group_name] \u001b[39m=\u001b[39m calculate_metrics(result, unprivileged_group)\n",
      "File \u001b[1;32md:\\Data-Privacy-Project\\src\\social bias frames\\..\\metric_utils.py:94\u001b[0m, in \u001b[0;36mcalculate_metrics\u001b[1;34m(df, group)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Data-Privacy-Project/src/social%20bias%20frames/../metric_utils.py?line=90'>91</a>\u001b[0m     df \u001b[39m=\u001b[39m df[(df[group])\u001b[39m.\u001b[39many(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)]\n\u001b[0;32m     <a href='file:///d%3A/Data-Privacy-Project/src/social%20bias%20frames/../metric_utils.py?line=92'>93</a>\u001b[0m y_true, y_pred, y_prob \u001b[39m=\u001b[39m df[target_column], df[prediction_column], df[probability_column]\n\u001b[1;32m---> <a href='file:///d%3A/Data-Privacy-Project/src/social%20bias%20frames/../metric_utils.py?line=93'>94</a>\u001b[0m auc \u001b[39m=\u001b[39m roc_auc_score(y_true, y_prob)\n\u001b[0;32m     <a href='file:///d%3A/Data-Privacy-Project/src/social%20bias%20frames/../metric_utils.py?line=95'>96</a>\u001b[0m results \u001b[39m=\u001b[39m [auc]\n\u001b[0;32m     <a href='file:///d%3A/Data-Privacy-Project/src/social%20bias%20frames/../metric_utils.py?line=96'>97</a>\u001b[0m methods \u001b[39m=\u001b[39m [accuracy_score, f1_score, precision_score, recall_score, true_positive_rate, false_positive_rate]\n",
      "File \u001b[1;32mc:\\Users\\khair\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:567\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_ranking.py?line=564'>565</a>\u001b[0m     labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y_true)\n\u001b[0;32m    <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_ranking.py?line=565'>566</a>\u001b[0m     y_true \u001b[39m=\u001b[39m label_binarize(y_true, classes\u001b[39m=\u001b[39mlabels)[:, \u001b[39m0\u001b[39m]\n\u001b[1;32m--> <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_ranking.py?line=566'>567</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _average_binary_score(\n\u001b[0;32m    <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_ranking.py?line=567'>568</a>\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[39m=\u001b[39;49mmax_fpr),\n\u001b[0;32m    <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_ranking.py?line=568'>569</a>\u001b[0m         y_true,\n\u001b[0;32m    <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_ranking.py?line=569'>570</a>\u001b[0m         y_score,\n\u001b[0;32m    <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_ranking.py?line=570'>571</a>\u001b[0m         average,\n\u001b[0;32m    <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_ranking.py?line=571'>572</a>\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_ranking.py?line=572'>573</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_ranking.py?line=573'>574</a>\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# multilabel-indicator\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_ranking.py?line=574'>575</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _average_binary_score(\n\u001b[0;32m    <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_ranking.py?line=575'>576</a>\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[39m=\u001b[39mmax_fpr),\n\u001b[0;32m    <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_ranking.py?line=576'>577</a>\u001b[0m         y_true,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_ranking.py?line=579'>580</a>\u001b[0m         sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[0;32m    <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_ranking.py?line=580'>581</a>\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\khair\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_base.py:75\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_base.py?line=71'>72</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m format is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n\u001b[0;32m     <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_base.py?line=73'>74</a>\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_base.py?line=74'>75</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m binary_metric(y_true, y_score, sample_weight\u001b[39m=\u001b[39;49msample_weight)\n\u001b[0;32m     <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_base.py?line=76'>77</a>\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[0;32m     <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_base.py?line=77'>78</a>\u001b[0m y_true \u001b[39m=\u001b[39m check_array(y_true)\n",
      "File \u001b[1;32mc:\\Users\\khair\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:337\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_ranking.py?line=334'>335</a>\u001b[0m \u001b[39m\"\"\"Binary roc auc score.\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_ranking.py?line=335'>336</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(y_true)) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_ranking.py?line=336'>337</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_ranking.py?line=337'>338</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_ranking.py?line=338'>339</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mis not defined in that case.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_ranking.py?line=339'>340</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_ranking.py?line=341'>342</a>\u001b[0m fpr, tpr, _ \u001b[39m=\u001b[39m roc_curve(y_true, y_score, sample_weight\u001b[39m=\u001b[39msample_weight)\n\u001b[0;32m    <a href='file:///c%3A/Users/khair/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/metrics/_ranking.py?line=342'>343</a>\u001b[0m \u001b[39mif\u001b[39;00m max_fpr \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m max_fpr \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "overall_results = {\n",
    "    'metrics': ['auc', 'accuracy', 'f1_score', 'precision', 'recall', 'true positive rate', 'false positive rate']\n",
    "}\n",
    "\n",
    "for group_key in group_map.keys():\n",
    "    subgroup_map = group_map[group_key]\n",
    "    privileged_group = subgroup_map['privileged']\n",
    "    unprivileged_group = subgroup_map['unprivileged']\n",
    "\n",
    "    privileged_group_name = ','.join(privileged_group)\n",
    "    unprivileged_group_name = ','.join(unprivileged_group)\n",
    "\n",
    "    overall_results[privileged_group_name] = calculate_metrics(result, privileged_group)\n",
    "    overall_results[privileged_group_name + '_DP'] = calculate_metrics(dp_result, privileged_group)\n",
    "\n",
    "    overall_results[unprivileged_group_name] = calculate_metrics(result, unprivileged_group)\n",
    "    overall_results[unprivileged_group_name + '_DP'] = calculate_metrics(dp_result, unprivileged_group)\n",
    "\n",
    "overall_results['Total'] = calculate_metrics(result, [])\n",
    "overall_results['Total_DP'] = calculate_metrics(dp_result, [])\n",
    "\n",
    "overall_results = pd.DataFrame(overall_results) \n",
    "overall_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_results.to_csv(os.path.join(model_folder, 'overall_resuls.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f82c0d4b75d1a522b549257adf6e3ea321f1ee050a595ab76efcf522f2572b2a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
