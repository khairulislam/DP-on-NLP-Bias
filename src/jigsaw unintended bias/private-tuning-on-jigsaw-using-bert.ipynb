{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook is done following \n* [Building text classifier with Differential Privacy](https://github.com/pytorch/opacus/blob/main/tutorials/building_text_classifier.ipynb)\n* [Fine-tuning with custom datasets](https://huggingface.co/transformers/v3.4.0/custom_datasets.html#seq-imdb)","metadata":{"id":"huyLXVRDUwFw"}},{"cell_type":"markdown","source":"# Intial Setup\nhttps://huggingface.co/docs/transformers/training","metadata":{"id":"n3CQPh6pRJpP"}},{"cell_type":"markdown","source":"## Install","metadata":{"id":"tB5WsXAHyBZv"}},{"cell_type":"code","source":"!pip install opacus\n# !pip install transformers\n!pip install datasets\nimport datasets","metadata":{"execution":{"iopub.status.busy":"2022-06-06T22:36:08.135593Z","iopub.execute_input":"2022-06-06T22:36:08.135901Z","iopub.status.idle":"2022-06-06T22:36:37.123096Z","shell.execute_reply.started":"2022-06-06T22:36:08.135822Z","shell.execute_reply":"2022-06-06T22:36:37.122315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import","metadata":{"id":"nxhRYG1UyFLJ"}},{"cell_type":"code","source":"from tqdm.auto import tqdm\nfrom transformers import AutoModelForSequenceClassification\nfrom torch.optim import AdamW\nimport torch\nfrom torch.utils.data import DataLoader\n\nfrom opacus.utils.batch_memory_manager import BatchMemoryManager\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport pandas as pd\nimport numpy as np\nimport gc\n\npd.set_option('display.max_columns', None)","metadata":{"id":"MjZvbCbYx-no","execution":{"iopub.status.busy":"2022-06-06T22:36:37.124863Z","iopub.execute_input":"2022-06-06T22:36:37.125204Z","iopub.status.idle":"2022-06-06T22:36:37.697753Z","shell.execute_reply.started":"2022-06-06T22:36:37.125131Z","shell.execute_reply":"2022-06-06T22:36:37.696941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-06-06T22:36:37.699162Z","iopub.execute_input":"2022-06-06T22:36:37.699416Z","iopub.status.idle":"2022-06-06T22:36:37.714565Z","shell.execute_reply.started":"2022-06-06T22:36:37.699381Z","shell.execute_reply":"2022-06-06T22:36:37.713805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"from dataclasses import dataclass\n\n@dataclass\nclass Config:\n    model_name = 'bert-base-uncased'\n    dataset_name = 'jigsaw-unintended-bias-in-toxicity-classification'\n    text_column = 'comment_text'\n    # if id column is string, replace that with an integer index during preprocessing\n    id_column = 'id'\n\n    # target in raw dataset. However, it will be renamed to `labels` here to facilitate training setup\n    raw_target_column = 'toxicity'\n    target_column = 'labels'\n    \n    undersample = True\n    need_to_split = True\n    \n    test_size = 0.2\n    max_seq_length = 128\n    seed = 2022\n    \n    # train config\n    batch_size = 64\n    learning_rate = 1e-3\n    epochs = 3\n    num_labels = 2\n    \n    # Private training config\n    delta_list = [5e-2, 1e-3, 1e-5]\n    noise_multiplier = 0.4\n    max_grad_norm = 1\n    max_physical_batch_size = 32","metadata":{"execution":{"iopub.status.busy":"2022-06-06T22:36:37.716525Z","iopub.execute_input":"2022-06-06T22:36:37.716781Z","iopub.status.idle":"2022-06-06T22:36:37.72479Z","shell.execute_reply.started":"2022-06-06T22:36:37.716746Z","shell.execute_reply":"2022-06-06T22:36:37.723869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Set seed","metadata":{}},{"cell_type":"code","source":"import random\n\ndef seed_torch(seed=7):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \n\nglobal_seed = Config.seed\nseed_torch(global_seed)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T22:36:37.726643Z","iopub.execute_input":"2022-06-06T22:36:37.727744Z","iopub.status.idle":"2022-06-06T22:36:37.737299Z","shell.execute_reply.started":"2022-06-06T22:36:37.727549Z","shell.execute_reply":"2022-06-06T22:36:37.73653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get device","metadata":{"id":"CSnXCK2k6KvV"}},{"cell_type":"code","source":"device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nprint(device)","metadata":{"id":"N01plY896Mps","outputId":"3d0d33d9-0b02-4ad8-c8c0-b227b57bf1fb","execution":{"iopub.status.busy":"2022-06-06T22:36:39.645193Z","iopub.execute_input":"2022-06-06T22:36:39.646101Z","iopub.status.idle":"2022-06-06T22:36:39.707514Z","shell.execute_reply.started":"2022-06-06T22:36:39.64606Z","shell.execute_reply":"2022-06-06T22:36:39.706374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load tokenized data\n\nFrom my [other notebook](https://www.kaggle.com/code/khairulislam/tokenize-jigsaw-comments). The dataset is tokenized from the [Jigsaw competition]( https://www.kaggle.com/competitions/jigsaw-unintended-bias-in-toxicity-classification) and [all_data.csv](https://www.kaggle.com/competitions/jigsaw-unintended-bias-in-toxicity-classification/data?select=all_data.csv)","metadata":{}},{"cell_type":"code","source":"text = Config.text_column\ntarget = Config.target_column\nroot = '/kaggle/input/tokenize-jigsaw-comments-using-bert/'","metadata":{"execution":{"iopub.status.busy":"2022-06-06T22:36:58.742843Z","iopub.execute_input":"2022-06-06T22:36:58.743093Z","iopub.status.idle":"2022-06-06T22:36:58.747246Z","shell.execute_reply.started":"2022-06-06T22:36:58.743065Z","shell.execute_reply":"2022-06-06T22:36:58.746179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n    \nwith open(root + 'train.pkl', 'rb') as input_file:\n    train_tokenized = pickle.load(input_file)\n    input_file.close()\n    \nwith open(root + 'validation.pkl', 'rb') as input_file:\n    validation_tokenized = pickle.load(input_file)\n    input_file.close()\n    \nwith open(root + 'test.pkl', 'rb') as input_file:\n    test_tokenized = pickle.load(input_file)\n    input_file.close()","metadata":{"execution":{"iopub.status.busy":"2022-06-06T22:37:01.031108Z","iopub.execute_input":"2022-06-06T22:37:01.031835Z","iopub.status.idle":"2022-06-06T22:37:05.88568Z","shell.execute_reply.started":"2022-06-06T22:37:01.031795Z","shell.execute_reply":"2022-06-06T22:37:05.884845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_tokenized)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T22:37:05.889122Z","iopub.execute_input":"2022-06-06T22:37:05.889774Z","iopub.status.idle":"2022-06-06T22:37:05.896785Z","shell.execute_reply.started":"2022-06-06T22:37:05.88974Z","shell.execute_reply":"2022-06-06T22:37:05.896027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove id column from the data to be batched\nid_column = Config.id_column \ntrain_tokenized = train_tokenized.remove_columns(id_column)\ntest_tokenized = test_tokenized.remove_columns(id_column)\nvalidation_tokenized = validation_tokenized.remove_columns(id_column)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T22:37:05.898575Z","iopub.execute_input":"2022-06-06T22:37:05.898774Z","iopub.status.idle":"2022-06-06T22:37:05.919934Z","shell.execute_reply.started":"2022-06-06T22:37:05.898743Z","shell.execute_reply":"2022-06-06T22:37:05.919323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Private Training","metadata":{"id":"Cf0mMuDWNQla"}},{"cell_type":"markdown","source":"## Data loader\n\n[How to choose batch size in DP](https://github.com/pytorch/opacus/blob/main/tutorials/building_text_classifier.ipynb)","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = Config.batch_size\n\ntrain_dataloader = DataLoader(train_tokenized, batch_size=BATCH_SIZE)\nvalidation_dataloader = DataLoader(validation_tokenized, batch_size=BATCH_SIZE*5)\ntest_dataloader = DataLoader(test_tokenized, batch_size=BATCH_SIZE*5)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T22:37:10.212773Z","iopub.execute_input":"2022-06-06T22:37:10.213093Z","iopub.status.idle":"2022-06-06T22:37:10.21822Z","shell.execute_reply.started":"2022-06-06T22:37:10.213061Z","shell.execute_reply":"2022-06-06T22:37:10.217154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model and optimizer","metadata":{}},{"cell_type":"code","source":"# add the utility script from File->Add utility script\nfrom train_utils import TrainUtil, ModelCheckPoint, EarlyStopping\n\nnum_labels = Config.num_labels\nmodel_name = Config.model_name\ntrain_util = TrainUtil(Config.id_column, Config.target_column, device)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T22:37:12.365656Z","iopub.execute_input":"2022-06-06T22:37:12.366387Z","iopub.status.idle":"2022-06-06T22:37:12.466322Z","shell.execute_reply.started":"2022-06-06T22:37:12.36634Z","shell.execute_reply":"2022-06-06T22:37:12.46566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load a fresh model each time\nmodel = TrainUtil.load_pretrained_model(model_name, num_labels)\n\n# Set the model to train mode (HuggingFace models load in eval mode)\nmodel = model.train().to(device)\nLEARNING_RATE = Config.learning_rate\n# Define optimizer\noptimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, eps=1e-8)\nEPOCHS = Config.epochs\n\n# https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html\nlr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1, verbose=True)","metadata":{"id":"2VJx_xjQNTaZ","execution":{"iopub.status.busy":"2022-06-06T22:37:14.437177Z","iopub.execute_input":"2022-06-06T22:37:14.437608Z","iopub.status.idle":"2022-06-06T22:37:44.819745Z","shell.execute_reply.started":"2022-06-06T22:37:14.437554Z","shell.execute_reply":"2022-06-06T22:37:44.818983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_dir = '' # f'dp models/{model_type}/{NOISE_MULTIPLIER*10}/'\nbest_model_path = os.path.join(result_dir, 'model.pt')\n\nif result_dir != '':\n    os.makedirs(result_dir, exist_ok=True)\n\ncheck_point = ModelCheckPoint(filepath=best_model_path)\nearly_stopping = EarlyStopping(patience=3, min_delta=0)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T22:37:44.821358Z","iopub.execute_input":"2022-06-06T22:37:44.821638Z","iopub.status.idle":"2022-06-06T22:37:44.827404Z","shell.execute_reply.started":"2022-06-06T22:37:44.821609Z","shell.execute_reply":"2022-06-06T22:37:44.825928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Privacy Engine","metadata":{"id":"b7EFOaY2NeiR"}},{"cell_type":"code","source":"from opacus import PrivacyEngine\n\nprivacy_engine = PrivacyEngine()","metadata":{"id":"R00MPKNsh205","execution":{"iopub.status.busy":"2022-06-06T22:37:44.828793Z","iopub.execute_input":"2022-06-06T22:37:44.829058Z","iopub.status.idle":"2022-06-06T22:37:44.839462Z","shell.execute_reply.started":"2022-06-06T22:37:44.829016Z","shell.execute_reply":"2022-06-06T22:37:44.838584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, optimizer, train_dataloader = privacy_engine.make_private(\n    module=model,\n    optimizer=optimizer,\n    data_loader=train_dataloader,\n    noise_multiplier=Config.noise_multiplier,\n    max_grad_norm=Config.max_grad_norm,\n    poisson_sampling=False,\n)","metadata":{"id":"Wta4qx6mNgqB","execution":{"iopub.status.busy":"2022-06-06T22:37:44.842452Z","iopub.execute_input":"2022-06-06T22:37:44.843101Z","iopub.status.idle":"2022-06-06T22:37:44.856755Z","shell.execute_reply.started":"2022-06-06T22:37:44.843066Z","shell.execute_reply":"2022-06-06T22:37:44.856068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loop","metadata":{}},{"cell_type":"code","source":"start_epoch = 1\n# load a previous model if there is any\n# model, optimizer, lr_scheduler, start_epoch = load_model(model, optimizer, lr_scheduler, device, filepath=best_model_path)\n\nfor epoch in range(start_epoch, EPOCHS+1):\n    gc.collect()\n    \n    with BatchMemoryManager(\n        data_loader=train_dataloader, \n        max_physical_batch_size=Config.max_physical_batch_size, \n        optimizer=optimizer\n    ) as memory_safe_data_loader:\n        train_loss, train_result, train_probs = train_util.dp_train(\n            model, optimizer, epoch, memory_safe_data_loader\n        )\n    val_loss, val_result, val_probs = train_util.evaluate(\n        model, validation_dataloader, epoch, 'Validation'\n    )\n\n    epsilons = []\n    for delta in Config.delta_list:\n        epsilons.append(privacy_engine.get_epsilon(delta))\n\n    print(\n      f\"Epoch: {epoch} | \"\n      f\"É›: {np.round(epsilons, 2)} |\"\n      f\"Train loss: {train_loss:.3f} | \"\n      f\"Train result: {train_result} |\\n\"\n      f\"Validation loss: {val_loss:.3f} | \"\n      f\"Validation result: {val_result} | \"\n    )\n    \n    loss = -val_result['f1']\n    lr_scheduler.step(loss)\n    check_point(model, optimizer, lr_scheduler, epoch, loss)\n    \n    early_stopping(loss)\n    if early_stopping.early_stop:\n        break\n    print()\n    # break","metadata":{"id":"RkZPY4iIUUOw","outputId":"aebf8df4-0009-4678-b0d5-392753e178e9","execution":{"iopub.status.busy":"2022-06-06T22:37:44.857932Z","iopub.execute_input":"2022-06-06T22:37:44.858632Z","iopub.status.idle":"2022-06-07T00:31:17.69822Z","shell.execute_reply.started":"2022-06-06T22:37:44.858595Z","shell.execute_reply":"2022-06-07T00:31:17.696167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the best model\nmodel, _, _, best_epoch = TrainUtil.load_model(model, optimizer, lr_scheduler, device, filepath=best_model_path)\n\ntrain_loss, train_result, train_probs = train_util.evaluate(model, train_dataloader, best_epoch, 'Train')\n# no need to reevaluate if the validation set if the last model is the best one\nif best_epoch != epoch:\n    val_loss, val_result, val_probs = train_util.evaluate(model, validation_dataloader, best_epoch, 'Validation')\ntest_loss, test_result, test_probs = train_util.evaluate(model, test_dataloader, best_epoch, 'Test')","metadata":{"execution":{"iopub.status.busy":"2022-06-07T00:31:49.573669Z","iopub.execute_input":"2022-06-07T00:31:49.573928Z","iopub.status.idle":"2022-06-07T01:28:12.989601Z","shell.execute_reply.started":"2022-06-07T00:31:49.573899Z","shell.execute_reply":"2022-06-07T01:28:12.988859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dump results and others","metadata":{}},{"cell_type":"code","source":"# load the original tokenized files, since we removed the id columns earlier\n# and id columns are needed for the result dumping part\nwith open(root + 'train.pkl', 'rb') as input_file:\n    train_tokenized = pickle.load(input_file)\n    input_file.close()\n    \nwith open(root + 'validation.pkl', 'rb') as input_file:\n    validation_tokenized = pickle.load(input_file)\n    input_file.close()\n    \nwith open(root + 'test.pkl', 'rb') as input_file:\n    test_tokenized = pickle.load(input_file)\n    input_file.close()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T01:28:12.991191Z","iopub.execute_input":"2022-06-07T01:28:12.991453Z","iopub.status.idle":"2022-06-07T01:28:13.785414Z","shell.execute_reply.started":"2022-06-07T01:28:12.991413Z","shell.execute_reply":"2022-06-07T01:28:13.784682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the results\ntrain_util.dump_results(\n    result_dir,train_probs, train_tokenized, \n    val_probs, validation_tokenized, test_probs, test_tokenized\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T01:28:13.786661Z","iopub.execute_input":"2022-06-07T01:28:13.787Z","iopub.status.idle":"2022-06-07T01:28:16.807196Z","shell.execute_reply.started":"2022-06-07T01:28:13.786963Z","shell.execute_reply":"2022-06-07T01:28:16.806344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save config","metadata":{}},{"cell_type":"code","source":"import json\n\nconfig_dict = dict(Config.__dict__)\n# exclude hidden variables\nkeys = list(config_dict.keys())\nfor key in keys:\n    if key.startswith('__'):\n        del config_dict[key]\n        \nwith open(os.path.join(result_dir, 'config.json'), 'w') as output:\n    json.dump(config_dict, output, indent=4)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T01:28:16.808965Z","iopub.execute_input":"2022-06-07T01:28:16.809259Z","iopub.status.idle":"2022-06-07T01:28:16.817039Z","shell.execute_reply.started":"2022-06-07T01:28:16.809222Z","shell.execute_reply":"2022-06-07T01:28:16.816377Z"},"trusted":true},"execution_count":null,"outputs":[]}]}