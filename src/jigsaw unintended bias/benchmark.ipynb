{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import sys\n",
    "# this adds the src folder in the sys path, where the metric_utils.py file is\n",
    "# not needed if this notebook is in the same folder, but uncomment to access from the data subfolders\n",
    "sys.path.append( '..' )\n",
    "from metric_utils import *\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'jigsaw unintended bias'\n",
    "model_name = 'bert'\n",
    "\n",
    "# change to f'../../results/{dataset_name}' when using inside one of the data subfolders\n",
    "result_folder = f'../../results/{dataset_name}'\n",
    "test_csv_filepath = os.path.join(result_folder, 'test.csv')\n",
    "\n",
    "model_folder = os.path.join(result_folder, model_name) # for this particular model\n",
    "result_filepath = os.path.join(model_folder, 'results.csv')\n",
    "dp_result_filepath = os.path.join(model_folder, 'results_dp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "The dataset can be preprocessed from the original dataset to be used here. To simplify things, I saved the preprocessed datasets during the tokenizing process as csv files and then downloaded them in the corresponding dataset folder of [`result`](../results/) directory.\n",
    "\n",
    "You can recreate the processed datasets using the tokenize notebooks for that particular dataset. That would give you train, test and validation csv files as well as the tokenized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7084460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7141509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  male  female  white  black\n",
       "0  7084460   NaN     NaN    NaN    NaN\n",
       "1  7141509   NaN     NaN    NaN    NaN"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.read_csv(result_filepath)\n",
    "dp_result = pd.read_csv(dp_result_filepath)\n",
    "\n",
    "df = pd.read_csv(test_csv_filepath)\n",
    "# df.drop(columns=['comment_text', 'labels'], inplace=True)\n",
    "# df.to_csv(test_csv_filepath, index=False)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only calculate test result\n",
    "result = result[result['split']=='test']\n",
    "dp_result = dp_result[dp_result['split']=='test']\n",
    "\n",
    "# drop split column\n",
    "result.drop(columns=['split'], inplace=True)\n",
    "dp_result.drop(columns=['split'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.merge(df, on=id_column, how='inner').reset_index(drop=True)\n",
    "dp_result = dp_result.merge(df, on=id_column, how='inner').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "      <th>probs</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7084460</td>\n",
       "      <td>1</td>\n",
       "      <td>0.712421</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7141509</td>\n",
       "      <td>1</td>\n",
       "      <td>0.885250</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7077814</td>\n",
       "      <td>1</td>\n",
       "      <td>0.731133</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7147990</td>\n",
       "      <td>0</td>\n",
       "      <td>0.289174</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7008066</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866662</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  labels     probs   male female  white  black\n",
       "0  7084460       1  0.712421  False  False  False  False\n",
       "1  7141509       1  0.885250  False  False  False  False\n",
       "2  7077814       1  0.731133  False  False  False  False\n",
       "3  7147990       0  0.289174  False  False  False  False\n",
       "4  7008066       1  0.866662  False  False  False  False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert probability to prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[prediction_column] = result[probability_column] >=0.5\n",
    "dp_result[prediction_column] = dp_result[probability_column] >=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['female', 'male', 'black', 'white']\n"
     ]
    }
   ],
   "source": [
    "group_map = {\n",
    "    'gender': {\n",
    "        'unprivileged':['female'],\n",
    "        'privileged':['male']\n",
    "    },\n",
    "    'race': {\n",
    "        'unprivileged':['black'],\n",
    "        'privileged': ['white']\n",
    "    }\n",
    "}\n",
    "\n",
    "identities = []\n",
    "for group_key in group_map.keys():\n",
    "    subgroup_map = group_map[group_key]\n",
    "    for subgroup_key in subgroup_map.keys():\n",
    "        identities.extend(subgroup_map[subgroup_key])\n",
    "\n",
    "print(identities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarize identity and target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = binarize(result, [target_column] + identities)\n",
    "dp_result = binarize(dp_result, [target_column] + identities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fairness_metrics</th>\n",
       "      <th>gender</th>\n",
       "      <th>gender_DP</th>\n",
       "      <th>race</th>\n",
       "      <th>race_DP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>demographic parity</td>\n",
       "      <td>0.979024</td>\n",
       "      <td>0.999544</td>\n",
       "      <td>0.707993</td>\n",
       "      <td>0.699021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Equality of Opportunity (w.r.t y = 1)</td>\n",
       "      <td>0.965559</td>\n",
       "      <td>0.962341</td>\n",
       "      <td>0.984192</td>\n",
       "      <td>0.921005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Equality of Opportunity (w.r.t y = 0)</td>\n",
       "      <td>0.970072</td>\n",
       "      <td>0.951749</td>\n",
       "      <td>0.986702</td>\n",
       "      <td>0.911523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Equality of Odds</td>\n",
       "      <td>0.967816</td>\n",
       "      <td>0.957045</td>\n",
       "      <td>0.985447</td>\n",
       "      <td>0.916264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unprotected-accuracy</td>\n",
       "      <td>0.741998</td>\n",
       "      <td>0.751503</td>\n",
       "      <td>0.495063</td>\n",
       "      <td>0.614220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>protected-accuracy</td>\n",
       "      <td>0.724578</td>\n",
       "      <td>0.717054</td>\n",
       "      <td>0.490212</td>\n",
       "      <td>0.568108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.733288</td>\n",
       "      <td>0.734279</td>\n",
       "      <td>0.492637</td>\n",
       "      <td>0.591164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        fairness_metrics    gender  gender_DP      race  \\\n",
       "0                     demographic parity  0.979024   0.999544  0.707993   \n",
       "1  Equality of Opportunity (w.r.t y = 1)  0.965559   0.962341  0.984192   \n",
       "2  Equality of Opportunity (w.r.t y = 0)  0.970072   0.951749  0.986702   \n",
       "3                       Equality of Odds  0.967816   0.957045  0.985447   \n",
       "4                   unprotected-accuracy  0.741998   0.751503  0.495063   \n",
       "5                     protected-accuracy  0.724578   0.717054  0.490212   \n",
       "6                               accuracy  0.733288   0.734279  0.492637   \n",
       "\n",
       "    race_DP  \n",
       "0  0.699021  \n",
       "1  0.921005  \n",
       "2  0.911523  \n",
       "3  0.916264  \n",
       "4  0.614220  \n",
       "5  0.568108  \n",
       "6  0.591164  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_results = {\n",
    "   # make sure your calculate bias method returns bias metrics in the same order\n",
    "   'fairness_metrics': ['demographic parity', 'Equality of Opportunity (w.r.t y = 1)',\n",
    "'Equality of Opportunity (w.r.t y = 0)', 'Equality of Odds', 'unprotected-accuracy',\n",
    "'protected-accuracy', 'accuracy']\n",
    "}\n",
    "\n",
    "for group_key in group_map.keys():\n",
    "   subgroup_map = group_map[group_key]\n",
    "   privileged_group = subgroup_map['privileged']\n",
    "   unprivileged_group = subgroup_map['unprivileged']\n",
    "\n",
    "   bias_results[group_key] = calculate_bias(result, privileged_group, unprivileged_group)\n",
    "   bias_results[group_key+'_DP'] = calculate_bias(dp_result, privileged_group, unprivileged_group)\n",
    "\n",
    "bias_results = pd.DataFrame(bias_results) \n",
    "bias_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_results.to_csv(os.path.join(model_folder, 'bias.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics</th>\n",
       "      <th>male</th>\n",
       "      <th>male_DP</th>\n",
       "      <th>female</th>\n",
       "      <th>female_DP</th>\n",
       "      <th>white</th>\n",
       "      <th>white_DP</th>\n",
       "      <th>black</th>\n",
       "      <th>black_DP</th>\n",
       "      <th>Total</th>\n",
       "      <th>Total_DP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.883173</td>\n",
       "      <td>0.824353</td>\n",
       "      <td>0.880977</td>\n",
       "      <td>0.823837</td>\n",
       "      <td>0.783018</td>\n",
       "      <td>0.733091</td>\n",
       "      <td>0.768420</td>\n",
       "      <td>0.725604</td>\n",
       "      <td>0.940320</td>\n",
       "      <td>0.897022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.724578</td>\n",
       "      <td>0.717054</td>\n",
       "      <td>0.741998</td>\n",
       "      <td>0.751503</td>\n",
       "      <td>0.490212</td>\n",
       "      <td>0.568108</td>\n",
       "      <td>0.495063</td>\n",
       "      <td>0.614220</td>\n",
       "      <td>0.865671</td>\n",
       "      <td>0.852272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.469885</td>\n",
       "      <td>0.474308</td>\n",
       "      <td>0.458351</td>\n",
       "      <td>0.531133</td>\n",
       "      <td>0.554480</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.581429</td>\n",
       "      <td>0.506101</td>\n",
       "      <td>0.464504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.345934</td>\n",
       "      <td>0.329144</td>\n",
       "      <td>0.326442</td>\n",
       "      <td>0.323969</td>\n",
       "      <td>0.367983</td>\n",
       "      <td>0.403058</td>\n",
       "      <td>0.390728</td>\n",
       "      <td>0.453735</td>\n",
       "      <td>0.357322</td>\n",
       "      <td>0.326056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.901493</td>\n",
       "      <td>0.820896</td>\n",
       "      <td>0.867052</td>\n",
       "      <td>0.783237</td>\n",
       "      <td>0.954178</td>\n",
       "      <td>0.888140</td>\n",
       "      <td>0.938370</td>\n",
       "      <td>0.809145</td>\n",
       "      <td>0.867167</td>\n",
       "      <td>0.807289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>true positive rate</td>\n",
       "      <td>0.901493</td>\n",
       "      <td>0.820896</td>\n",
       "      <td>0.867052</td>\n",
       "      <td>0.783237</td>\n",
       "      <td>0.954178</td>\n",
       "      <td>0.888140</td>\n",
       "      <td>0.938370</td>\n",
       "      <td>0.809145</td>\n",
       "      <td>0.867167</td>\n",
       "      <td>0.807289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>false positive rate</td>\n",
       "      <td>0.307320</td>\n",
       "      <td>0.301668</td>\n",
       "      <td>0.277392</td>\n",
       "      <td>0.253417</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.570760</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>0.482283</td>\n",
       "      <td>0.134458</td>\n",
       "      <td>0.143850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               metrics      male   male_DP    female  female_DP     white  \\\n",
       "0                  auc  0.883173  0.824353  0.880977   0.823837  0.783018   \n",
       "1             accuracy  0.724578  0.717054  0.741998   0.751503  0.490212   \n",
       "2             f1_score  0.500000  0.469885  0.474308   0.458351  0.531133   \n",
       "3            precision  0.345934  0.329144  0.326442   0.323969  0.367983   \n",
       "4               recall  0.901493  0.820896  0.867052   0.783237  0.954178   \n",
       "5   true positive rate  0.901493  0.820896  0.867052   0.783237  0.954178   \n",
       "6  false positive rate  0.307320  0.301668  0.277392   0.253417  0.711111   \n",
       "\n",
       "   white_DP     black  black_DP     Total  Total_DP  \n",
       "0  0.733091  0.768420  0.725604  0.940320  0.897022  \n",
       "1  0.568108  0.495063  0.614220  0.865671  0.852272  \n",
       "2  0.554480  0.551724  0.581429  0.506101  0.464504  \n",
       "3  0.403058  0.390728  0.453735  0.357322  0.326056  \n",
       "4  0.888140  0.938370  0.809145  0.867167  0.807289  \n",
       "5  0.888140  0.938370  0.809145  0.867167  0.807289  \n",
       "6  0.570760  0.724409  0.482283  0.134458  0.143850  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_results = {\n",
    "    'metrics': ['auc', 'accuracy', 'f1_score', 'precision', 'recall', 'false positive rate']\n",
    "}\n",
    "\n",
    "for group_key in group_map.keys():\n",
    "    subgroup_map = group_map[group_key]\n",
    "    privileged_group = subgroup_map['privileged']\n",
    "    unprivileged_group = subgroup_map['unprivileged']\n",
    "\n",
    "    privileged_group_name = ','.join(privileged_group)\n",
    "    unprivileged_group_name = ','.join(unprivileged_group)\n",
    "\n",
    "    overall_results[privileged_group_name] = calculate_metrics(result, privileged_group)\n",
    "    overall_results[privileged_group_name + '_DP'] = calculate_metrics(dp_result, privileged_group)\n",
    "\n",
    "    overall_results[unprivileged_group_name] = calculate_metrics(result, unprivileged_group)\n",
    "    overall_results[unprivileged_group_name + '_DP'] = calculate_metrics(dp_result, unprivileged_group)\n",
    "\n",
    "overall_results['Total'] = calculate_metrics(result, [])\n",
    "overall_results['Total_DP'] = calculate_metrics(dp_result, [])\n",
    "\n",
    "overall_results = pd.DataFrame(overall_results) \n",
    "overall_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_results.to_csv(os.path.join(model_folder, 'overall_results.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f82c0d4b75d1a522b549257adf6e3ea321f1ee050a595ab76efcf522f2572b2a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
